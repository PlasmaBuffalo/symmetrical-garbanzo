{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# News Classification\n",
    "\n",
    "Use Jupyter Notebooks to create a News Classifier with Multimodal Naive Bayes Classification.\n",
    "\n",
    "## Read in the Data:\n",
    "\n",
    "Use the Kaggle News Category Classification data set for this project. Note this is a JSON dataset and will be read in differently than a CSV.\n",
    "\n",
    "Markdown help:\n",
    "https://www.markdownguide.org/cheat-sheet/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This block will read in the data, converting from JSON to a dataframe\n",
    "\n",
    "import pandas, json\n",
    "\n",
    "df = pandas.read_json(\"News_Category_Dataset_v3.json\", lines=True)\n",
    "\n",
    "# let's see what categories/keys we're working with\n",
    "# here's an example:\n",
    "# {\n",
    "    # \"link\": \"https://www.huffpost.com/entry/covid-boosters-uptake-us_n_632d719ee4b087fae6feaac9\",\n",
    "    # \"headline\": \"Over 4 Million Americans Roll Up Sleeves For Omicron-Targeted COVID Boosters\",\n",
    "    # \"category\": \"U.S. NEWS\",\n",
    "    # \"short_description\": \"Health experts said it is too early to predict whether demand would match up with the 171 million doses of the new boosters the U.S. ordered for the fall.\",\n",
    "    # \"authors\": \"Carla K. Johnson, AP\",\n",
    "    # \"date\": \"2022-09-23\"\n",
    "# }\n",
    "\n",
    "# so we have\n",
    "# keys = [link, headline, category, short_description, authors, date]\n",
    "\n",
    "# let's check to make sure all our data is at least somewhat valid\n",
    "# print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Test Data: \n",
    "\n",
    "Before you start building your classifier, remove 20% of the data and place it in a separate table; this will be your testing dataset. \n",
    "\n",
    "Once you have created your model (Steps 0 and 1) with the other 80% of the data you will test to see how accurate your model is by having the program categorize the records in your testing data set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167621\n"
     ]
    }
   ],
   "source": [
    "# this block will partition our data into the 80-20 split we need\n",
    "\n",
    "# let's find out the shape of our dataframe\n",
    "\n",
    "# print(df.shape) returns (209527, 6), which means we have 209527 rows and 6 columns\n",
    "\n",
    "# we'll calculate the last 20% and reserve those entries for testing\n",
    "\n",
    "test_index_start = int(df.shape[0]*4/5)\n",
    "\n",
    "model_bounds:tuple = (0, test_index_start-1)\n",
    "\n",
    "test_bounds:tuple = (test_index_start, df.shape[0])\n",
    "\n",
    "print(model_bounds)\n",
    "\n",
    "print(test_bounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Stop Words:\n",
    "\n",
    "Just like in your first Project you should remove the Stop Words in all of the articles before building your model or testing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this block will help remove stop words from our 80% before testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Classifier:\n",
    "\n",
    "You may use whatever python libraries you wish but you should write the code for each of the four steps in the Multimodal Naive Bayes Classification yourself.\n",
    "\n",
    "- Step 0: Laplace Smoothing (remember this is for word counts not the categories’ probabilities)\n",
    "\n",
    "- Step 1: Find probabilities for each word for each category\n",
    "\n",
    "- Step 2: Calculate the probability that a record in the testing data set is part of each category.\n",
    "\n",
    "- Step 3: Compare probabilities calculated in Step 2. Choose the largest probability to assign the category tag for the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this block will be our classifier function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Results:\n",
    "\n",
    "Since you have the categories that the test data was originally sorted into you can compare the predicted probabilities with the original classifications of the news articles. Report the overall effectiveness of your classifier as a percentage of news items categorized correctly. This should be done as a percentage across all the data in the test data set as well as the percent in each category that were categorized correctly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we can print the effectiveness of our classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Documentation:\n",
    "\n",
    "Make sure to comment your code and give credit to any sources you used in creating your code.\n",
    "\n",
    "## Reflection:\n",
    "\n",
    "Create a document with the answers to the following questions. This should be formatted with each numbered question as the start of its own section, with the answer below it. Make sure your document has a title and your name on it.\n",
    "\n",
    "### Technical:\n",
    "\n",
    "1. How is JSON formatted? Give an example with an explanation.\n",
    "2. Why were the stop words removed from the text? If you don’t do this step in your code what changes? What other steps could you take along the same lines to improve your program?\n",
    "3. Why was Laplace Smoothing done?\n",
    "4. This is a machine learning algorithm. What is the purpose of training and testing data sets? Why might 20% of the data have been reserved for testing, not more, not less?\n",
    "5. How did the size of data affected the time complexity? How did you manage this challenge?\n",
    "\n",
    "### Process:\n",
    "\n",
    "1. How did you approach the assignment? Did you give yourself enough time?\n",
    "2. What challenges did you have with the code?\n",
    "3. What did you learn while working on this assignment?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
