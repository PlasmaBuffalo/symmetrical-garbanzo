{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "The goal of this milestone is for you to scrape data from an actual website and start to analyze the results. The project should be completed in individually in python without the assistance of any artificial intelligences.\n",
    "\n",
    "Web Scraper - Take all of the text from the top 20 articles coming from one of the following web news sources:\n",
    "\n",
    "espn.com\n",
    "cnn.com\n",
    "goodblacknews.org\n",
    "huffingtonpost.com\n",
    "ign.com\n",
    "theonion.com\n",
    "\n",
    "Statistics - Print a list of the titles of the web pages you are pulling text from and then print the mean and median number of words for all 20 articles.\n",
    "\n",
    "Visualize - Create a Word Cloud using your list of most common words that shows the top 50 (or up to 200) words and a bar chart to show the relative frequencies of the top 15 most frequent words. (Note: these should be words that the average viewer of the website would see, not code from the html)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A bit of code: downloads the linked HTML page into this notebook's folder\n",
    "#code example is from https://pythonexamples.org/python-download-from-url/\n",
    "\"\"\"import requests\n",
    "\n",
    "URL = \"https://pythonexamples.org/\"\n",
    "response = requests.get(URL)\n",
    "\n",
    "with open(\"download.html\", \"wb\") as htmlFile:\n",
    "    htmlFile.write(response.content)\n",
    "    print('Download completed.')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plan:\n",
    "-Download main webpage: https://www.cnn.com\n",
    "-Have it figure out what is an article and what is not\n",
    "-Generate a list of links to articles\n",
    "-For the first 20 relevant links, download each link's HTML to this folder\n",
    "-For each page, I need: page title, word count, list of all words\n",
    "-This comes from <title>,<h1-h6>,<li>,<p>,<a>,<article>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code that downloads the main CNN page as a file\n",
    "import requests\n",
    "\n",
    "base_url = \"https://www.cnn.com\"\n",
    "response = requests.get(base_url)\n",
    "\n",
    "with open(\"main_page.html\", \"wb\") as htmlFile:\n",
    "    htmlFile.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code that searches through main news page and returns a number of article links\n",
    "#import os\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "#how many links I want to grab from the given page\n",
    "linkCount = 20\n",
    "\n",
    "with open(\"main_page.html\", \"wb\") as htmlFile:\n",
    "    print()\n",
    "    \n",
    "#at the end, delete the main page we took all the links from\n",
    "#os.remove(\"main_page.html\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
